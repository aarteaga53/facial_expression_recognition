# -*- coding: utf-8 -*-
"""Assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lZVpA7VCqolWTVAlzhpyYa8x00eYF0Ck
"""

from google.colab import drive
drive.mount('/content/drive')

# all imports used
import csv
import os
import numpy as np
import pandas as pd
from PIL import Image
import torch
from torch import nn
import torchvision.models as models
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.io import read_image
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt

device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)

"""Variables and Hyperparameters"""

# initialize hyperparameters
learning_rate = 0.008
batch_size = 32
epochs = 50
weight_decay = 0.0001
momentum = 0.9

# global variables to track loss
global loss_train # training losses
global loss_test # testing losses
loss_train = []
loss_test = []

classes = ['angry', 'happy', 'neutral'] # facial expressions

"""Create a CustomImageDataset Class to Hold Data"""

class CustomImageDataset(Dataset):
    def __init__(self, data, labels=None, transform=None, target_transform=None):
        self.img_labels = labels
        self.img_data = data
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_data)

    def __getitem__(self, idx):
        # gets the image pixels from images array
        img = self.img_data[idx]
        # converts pixels to image
        image = Image.fromarray(img.astype(np.uint8).reshape(48, 48))

        if self.transform:
            image = self.transform(image)

        # returns label if there is one, otherwise just image
        if self.img_labels is not None:
          label = self.img_labels.iloc[idx, 0]

          if self.target_transform:
            label = self.target_transform(label)

          return image, label
        else:
          return image

"""Read Data"""

# read data files and get list of pixels
data = pd.read_csv('/content/drive/MyDrive/CS4210/train_data.csv', header=None).values
labels = pd.read_csv('/content/drive/MyDrive/CS4210/train_target.csv', header=None)
test = pd.read_csv('/content/drive/MyDrive/CS4210/test_data.csv', header=None).values

"""Create Transforms to Augment Data"""

# Crops the images and resizes them to original size
transform_resize = transforms.Compose([
    transforms.RandomCrop(32),
    transforms.Resize(48),
    transforms.ToTensor(),
    transforms.Normalize((0.4978), (0.2527))
])

# Rotates the images
transform_rotate = transforms.Compose([
    transforms.RandomRotation(180),
    transforms.ToTensor(),
    transforms.Normalize((0.4978), (0.2527))
])

# Normalizes the images
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4978), (0.2527))
])

"""Create Datasets"""

# Datasets of augmented data
dataset_resize = CustomImageDataset(data, labels, transform=transform_resize)
dataset_rotate = CustomImageDataset(data, labels, transform=transform_rotate)

# Dataset of full data
dataset = CustomImageDataset(data, labels, transform=transform)

# Splits full data set into training and validation sets
train_data, val_data = torch.utils.data.random_split(dataset, [len(dataset) - len(test), len(test)])
test_data = CustomImageDataset(test, transform=transform)

"""Create Dataloaders"""

# create dataloaders for training, validation, and testing
train_dataloader = DataLoader(train_data + dataset_rotate + dataset_resize, batch_size=batch_size, shuffle=True)
val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)
test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)

"""Display First Image and Labels of Datasets"""

# Display first image and label for training.
train_features, train_labels = next(iter(train_dataloader))
print(f"Feature batch shape: {train_features.size()}")
print(f"Labels batch shape: {train_labels.size()}")
img = train_features[0].squeeze()
label = train_labels[0]
plt.imshow(img, cmap="gray")
plt.show()
print(f"Label: {classes[label]}")

# Display first image and label for validation.
val_features, val_labels = next(iter(val_dataloader))
print(f"Feature batch shape: {val_features.size()}")
print(f"Labels batch shape: {val_labels.size()}")
img = val_features[0].squeeze()
label = val_labels[0]
plt.imshow(img, cmap="gray")
plt.show()
print(f"Label: {classes[label]}")

# Display first image for testing.
test_features = next(iter(test_dataloader))
print(f"Feature batch shape: {test_features.size()}")
img = test_features[0].squeeze()
plt.imshow(img, cmap="gray")
plt.show()

"""Neural Network Class (Not Used)"""

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(48*48, 1024),
            nn.ReLU(),
            nn.Linear(1024, 1024),
            nn.ReLU(),
            nn.Linear(1024, 3),
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

"""Convolutional Neural Network Class (Used)"""

class Network(nn.Module):
    def __init__(self):
        super(Network, self).__init__()
        self.layers = nn.Sequential(
            nn.Conv2d(1, 8, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(8, 32, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(256, 512, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Flatten(),
            nn.Linear(512*6*6, 4096),
            nn.ReLU(),
            nn.Linear(4096, 4096),
            nn.ReLU(),
            nn.Linear(4096, 3)
        )

    def forward(self, x):
        x = self.layers(x)
        return x

"""Create Model"""

model = Network().to(device) # convolutional neural network
print(model)

"""Training and Testing Loop Functions"""

def train_loop(dataloader, model, loss_fn, optimizer):
    global loss_train
    total = 0 # the total loss in the epoch

    size = len(dataloader.dataset)
    for batch, (X, y) in enumerate(dataloader):
        # Compute prediction and loss
        pred = model(X.cuda())
        loss = loss_fn(pred, y.cuda())
        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total += loss.item() # adds loss from each batch

        if batch % 100 == 0:
            loss, current = loss.item(), batch * len(X)
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")

    # appends the average loss at the epoch
    loss_train.append(total / len(dataloader))

def test_loop(dataloader, model, loss_fn):
    global loss_test
    total = 0 # the total loss in the epoch

    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    test_loss, correct = 0, 0

    with torch.no_grad():
        for X, y in dataloader:
            pred = model(X.cuda())
            test_loss += loss_fn(pred, y.cuda()).item()
            correct += (pred.argmax(1) == y.cuda()).type(torch.float).sum().item()

    test_loss /= num_batches
    correct /= size

    # appends the average loss in the epoch
    loss_test.append(test_loss)

    print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \n")

# Initialize the loss function
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)

"""Train the model over desired epochs and test"""

# iterate over epochs
for t in range(epochs):
    print(f"Epoch {t+1}\n-------------------------------")
    # train data
    model.train()
    train_loop(train_dataloader, model, loss_fn, optimizer)
    # test accuracy after each training
    model.eval()
    test_loop(val_dataloader, model, loss_fn)
print("Done!")

"""Plot Training and Testing Loss"""

plt.plot([i for i in range(len(loss_train))], loss_train, label='Training')
plt.plot([i for i in range(len(loss_test))], loss_test, label='Testing')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.plot()

"""Save and Load Model"""

# save the model weights
torch.save(model.state_dict(), '/content/drive/MyDrive/CS4210/my_model_weights.pth')

# load the model weights
model = Network().to(device)
model.load_state_dict(torch.load('/content/drive/MyDrive/CS4210/my_model_weights.pth'))
model.eval()

"""Predict Facial Expression of Test Data and Output to CSV File"""

# Predict all facial expressions of data in dataloader
# Input: Data to predict, NeuralNetwork model
# Ouput: list of images and their predictions
def predict_expression(dataloader, model):
  preds = []

  for X in dataloader:
    pred = model(X.cuda())
    _, prediction = torch.max(pred, 1)
    preds.append((X, prediction))

  return preds

preds = predict_expression(test_dataloader, model)
id = 0 # id number for each image

# create a csv file and write header
f = open('/content/drive/MyDrive/CS4210/test_predictions.csv', 'w', newline='')
writer = csv.writer(f)
writer.writerow(['Id', 'Category'])

# iterate through the predictions and write to csv file along image id
for i, j in preds:
  writer.writerow([id, j.item()])
  id += 1 # increment id

f.close()

"""Predict Facial Expression of Batches in Test DataLoader and Display Image and Prediction"""

# Predict a random batch of data from dataloader
# Input: Data to predict, NeuralNetwork model
# Ouput: the images and their predictions
def test_batch(dataloader, model):
  # loads a batch of data
  X = next(iter(dataloader))
  # predicts on the batch
  pred = model(X.cuda())
  _, prediction = torch.max(pred, 1)
  return X, prediction

test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)
images, targets = test_batch(test_dataloader, model)

# Display the first image of the batch and the predicted label from the batch
img = images[0].squeeze()
label = targets[0]
plt.imshow(img, cmap="gray")
plt.show()
print(f"Label: {classes[label]}")